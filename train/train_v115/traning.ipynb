{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys, os\n",
    "import argparse\n",
    "import random\n",
    "# import math\n",
    "# os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "# from modeling import EMA\n",
    "# from model_factory.utils import build_model\n",
    "from model_factory.datasets.videolmdb_dataset import LabelVideoLmdbDataSet\n",
    "from model_factory.backbones.swinv2 import SwinTransformerV2\n",
    "from model_factory.recognizers.simple_selfsup_recognizer import SimpleContrastRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unrecognized arguments ['--f=c:\\\\Users\\\\pc\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v385502f187e5143fb16482878396710704399a1af.json'] will be ignored.\n"
     ]
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', type=str, default=\"\")\n",
    "    parser.add_argument('--batch_size', type=int, default=16)\n",
    "    parser.add_argument('--num_workers', type=int, default=0)\n",
    "    parser.add_argument('--lr', type=float, default=5e-5)\n",
    "    parser.add_argument('--t', type=float, default=0.05)\n",
    "    parser.add_argument('--margin', type=float, default=0.0)\n",
    "    parser.add_argument('--print_freq', type=int, default=10)\n",
    "    parser.add_argument('--work_dir', type=str, default='')\n",
    "    # parser.add_argument('--resume', type=str, default='')\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--warmup_ratio', type=float, default=0.1)\n",
    "    parser.add_argument('--clip_grad_norm', type=float, default=1)\n",
    "    # parser.add_argument('--local_rank', type=int, default=0)  \n",
    "    # parser.add_argument('--rank', type=int, default=0)\n",
    "    parser.add_argument('--world_size', type=int, default=-1)\n",
    "    parser.add_argument('--seed', type=int, default=1234)\n",
    "    parser.add_argument('--instance_mask', action='store_true', default=False)\n",
    "    parser.add_argument('--entropy_loss', action='store_true', default=False)\n",
    "    parser.add_argument('--do_ema', action='store_true', default=False)\n",
    "    parser.add_argument('--do_fgm', action='store_true', default=False)\n",
    "    parser.add_argument('--entropy_weight', type=float, default=30)\n",
    "    parser.add_argument('--ici_weight', type=float, default=1.)\n",
    "    # parser.add_argument('--fp16', action='store_true', default=False)  \n",
    "    parser.add_argument('--checkpointing', action='store_true', default=False)\n",
    "    parser.add_argument('--concat_dataset', action='store_true', default=False)\n",
    "    parser.add_argument('--product_loss', action='store_true', default=False)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    if unknown:\n",
    "        print(f\"Warning: Unrecognized arguments {unknown} will be ignored.\")\n",
    "    return args\n",
    "\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = r\"D:\\learn\\giaotrinh\\new\\video similarity\\train_v115_mycode\"\n",
    "batch_size = args.batch_size\n",
    "num_workers = args.num_workers\n",
    "lr = args.lr\n",
    "epochs = args.epochs\n",
    "print_freq = args.print_freq\n",
    "warmup_ratio = args.warmup_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "setup_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.makedirs(f\"{work_dir}/checkpoints\", exist_ok=True) \n",
    "logger = logging.getLogger('log')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "ch = logging.StreamHandler(stream=sys.stdout)\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"[%(levelname)s: %(asctime)s] %(message)s\")\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fh = logging.FileHandler(work_dir + '/log.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(r\"D:\\learn\\giaotrinh\\new\\video similarity\\train_v115_mycode\\config_v115.py\")\n",
    "cfg_data = cfg.data\n",
    "cfg_model = cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Num vids 1014\n",
      "### Samples R115029 R115546 R115411 R115190 R115295\n",
      "#### NUM ANN DICT 99.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LabelVideoLmdbDataSet(\n",
    "        vids_path=cfg_data['vids_path'],\n",
    "        meta_path=cfg_data['meta_path'],\n",
    "        preprocess=cfg_data['preprocess'],\n",
    "        lmdb_path=cfg_data['lmdb_path'],\n",
    "        lmdb_size=cfg_data['lmdb_size'],\n",
    "        width=cfg_data['width'],\n",
    "        ann_path=cfg_data['ann_path'],\n",
    "        arg_lmdb_path=cfg_data['arg_lmdb_path'],\n",
    "        probs=cfg_data['probs'],\n",
    "        crop=cfg_data['crop'],\n",
    "        mixup=cfg_data['mixup'],)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3610.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from: D:/learn/giaotrinh/new/video similarity/train_v115_mycode/checkpoints/swinv2_base_patch4_window12to16_192to256_22kto1k_ft.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleContrastRecognizer(\n",
       "  (backbone): SwinTransformerV2(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        dim=128, input_resolution=(64, 64), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=128, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=4\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=128, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=128, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=4\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(64, 64), dim=128\n",
       "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicLayer(\n",
       "        dim=256, input_resolution=(32, 32), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=256, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=8\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=256, input_resolution=(32, 32), num_heads=8, window_size=16, shift_size=8, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=256, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=8\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.026)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(32, 32), dim=256\n",
       "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicLayer(\n",
       "        dim=512, input_resolution=(16, 16), depth=18\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.035)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.043)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.052)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.061)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.070)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.078)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.087)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.096)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.104)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.113)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.122)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.130)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.139)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.148)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.157)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.165)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.174)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): SwinTransformerBlock(\n",
       "            dim=512, input_resolution=(16, 16), num_heads=16, window_size=16, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=512, window_size=(16, 16), pretrained_window_size=(12, 12), num_heads=16\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.183)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(16, 16), dim=512\n",
       "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicLayer(\n",
       "        dim=1024, input_resolution=(8, 8), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(8, 8), pretrained_window_size=(6, 6), num_heads=32\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.191)\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=1024, input_resolution=(8, 8), num_heads=32, window_size=8, shift_size=0, mlp_ratio=4.0\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=1024, window_size=(8, 8), pretrained_window_size=(6, 6), num_heads=32\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.200)\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_proj): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_cfg = cfg_model[\"backbone\"]\n",
    "model = SimpleContrastRecognizer(backbone=backbone_cfg)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = AdamW(model.parameters(), lr=lr)\n",
    "batch_size = batch_size  \n",
    "stepsize = (len(train_dataset) // batch_size + 1)\n",
    "total_steps = (len(train_dataset) // batch_size + 1) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=warmup_ratio * total_steps, num_training_steps=total_steps)\n",
    "\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_gather(local_rank, world_size, **tensors):\n",
    "    tensors = list(tensors.values())\n",
    "    _dims = [t.shape[-1] for t in tensors]\n",
    "    tensors = torch.cat(tensors, dim=-1)\n",
    "    tensors_all = [torch.zeros_like(tensors) for _ in range(world_size)]\n",
    "    tensors_all[local_rank] = tensors\n",
    "    tensors_all = torch.cat(tensors_all, dim=0)\n",
    "\n",
    "    results = list()\n",
    "    dimStart = 0\n",
    "    assert sum(_dims) == tensors_all.shape[-1]\n",
    "    for d in _dims:\n",
    "        results.append(tensors_all[..., dimStart: dimStart + d])\n",
    "        dimStart += d\n",
    "\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_loss_fn(emb_a, emb_b, temperature, margin=0):\n",
    "    bz = emb_a.size(0)\n",
    "    emb = torch.cat([emb_a, emb_b], dim=0)\n",
    "    sims = emb @ emb.t()\n",
    "    diag = torch.eye(sims.size(0), device=sims.device)\n",
    "    \n",
    "    small_value = torch.tensor(-10000., device=sims.device, dtype=sims.dtype)\n",
    "    sims = torch.where(diag.eq(0), sims, small_value)\n",
    "    # Ground truth for positive pairs\n",
    "    gt = torch.cat([torch.arange(bz, device=sims.device) + bz, torch.arange(bz, device=sims.device)], dim=0)\n",
    "    # Compute loss\n",
    "    if margin > 0:\n",
    "        loss_ = F.cross_entropy((sims - diag * margin) / temperature, gt)\n",
    "    else:\n",
    "        loss_ = F.cross_entropy(sims / temperature, gt)\n",
    "\n",
    "    if loss_.dim() > 0:\n",
    "        loss_ = loss_.mean() # thm\n",
    "\n",
    "    return loss_\n",
    "\n",
    "def entropy_loss_fn(sims):\n",
    "    device = sims.device\n",
    "    diag = torch.eye(sims.size(0), device=device)\n",
    "    local_mask = (1 - diag)\n",
    "    small_value = torch.tensor(-10000., device=device, dtype=sims.dtype)\n",
    "    # Mask out diagonal to find maximum non-matching similarity\n",
    "    max_non_match_sim = torch.where(local_mask.bool(), sims, small_value).max(dim=1)[0]\n",
    "    # Compute closest distance and apply log\n",
    "    closest_distance = (1 / 2 - max_non_match_sim / 2).clamp(min=1e-6).sqrt()\n",
    "    entropy_loss_ = -closest_distance.log().mean() * args.entropy_weight\n",
    "\n",
    "    if entropy_loss_.dim() > 0:\n",
    "        entropy_loss_ = entropy_loss_.mean()\n",
    "\n",
    "    return entropy_loss_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_data):\n",
    "    # Move video data to GPU if it's not already there\n",
    "    vid_a, vid_b = batch_data[\"vid_a\"].cuda(), batch_data[\"vid_b\"].cuda()\n",
    "    bz = batch_data[\"img_a\"].size(0)\n",
    "    \n",
    "    # Move image data to GPU\n",
    "    device = batch_data[\"img_a\"].device\n",
    "    cat_x = torch.cat([batch_data[\"img_a\"], batch_data[\"img_b\"]], dim=0).to(device)\n",
    "\n",
    "    # Process embeddings\n",
    "    embeds = model(x=cat_x).to(device)  # Forward pass through the model\n",
    "    embeds_norm = embeds / embeds.norm(dim=1, keepdim=True)  # Normalize embeddings\n",
    "    emb_a, emb_b = embeds[:bz], embeds[bz:2 * bz]\n",
    "    emb_a_norm, emb_b_norm = embeds_norm[:bz], embeds_norm[bz:2 * bz]\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    sims_norm = emb_a_norm @ emb_b_norm.t()\n",
    "\n",
    "    # Calculate loss\n",
    "    if args.product_loss:\n",
    "        match_sim = (emb_a_norm * emb_b_norm).sum(dim=1)\n",
    "        entropy_loss_ = (1 - match_sim).exp().mean().to(device)\n",
    "    else: \n",
    "        entropy_loss_ = entropy_loss_fn(sims_norm)\n",
    "\n",
    "    # Contrastive loss\n",
    "    ici_loss_ = contrast_loss_fn(emb_a_norm, emb_b_norm, args.t) * args.ici_weight\n",
    "\n",
    "    return ici_loss_, entropy_loss_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training model\n",
      "Batch: 0\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:06:56,648] Epoch 0 Batch 0 Loss 59.220, ICI Loss 3.391, Entropy loss 55.829.\n",
      "Error encountered while sampling pair 17: cannot identify image file <_io.BytesIO object at 0x000001D65774B830>\n",
      "Batch: 1\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 2\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 3\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 69: cannot identify image file <_io.BytesIO object at 0x000001D65774A200>\n",
      "Error encountered while sampling pair 71: cannot identify image file <_io.BytesIO object at 0x000001D657748270>\n",
      "Batch: 4\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 5\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 6\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 118: cannot identify image file <_io.BytesIO object at 0x000001D361009CB0>\n",
      "Batch: 7\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 8\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 158: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 9\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 10\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:11:45,308] Epoch 0 Batch 10 Loss 56.757, ICI Loss 3.296, Entropy loss 53.462.\n",
      "Error encountered while sampling pair 182: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 11\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 198: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 12\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 13\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 228: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 14\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 249: cannot identify image file <_io.BytesIO object at 0x000001D361302ED0>\n",
      "Batch: 15\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 16\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 17\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 293: cannot identify image file <_io.BytesIO object at 0x000001D657748310>\n",
      "Batch: 18\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 316: cannot identify image file <_io.BytesIO object at 0x000001D3613023E0>\n",
      "Batch: 19\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 20\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:17:02,228] Epoch 0 Batch 20 Loss 40.816, ICI Loss 3.401, Entropy loss 37.414.\n",
      "Error encountered while sampling pair 339: cannot identify image file <_io.BytesIO object at 0x000001D361148630>\n",
      "Batch: 21\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 22\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 23\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 384: cannot identify image file <_io.BytesIO object at 0x000001D361302E30>\n",
      "Batch: 24\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 415: cannot identify image file <_io.BytesIO object at 0x000001D361029030>\n",
      "Batch: 25\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 26\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 27\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 460: cannot identify image file <_io.BytesIO object at 0x000001D657748400>\n",
      "Batch: 28\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 477: cannot identify image file <_io.BytesIO object at 0x000001D657748D60>\n",
      "Batch: 29\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 30\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:21:53,364] Epoch 0 Batch 30 Loss 30.136, ICI Loss 3.861, Entropy loss 26.275.\n",
      "Error encountered while sampling pair 501: cannot identify image file <_io.BytesIO object at 0x000001D3613023E0>\n",
      "Batch: 31\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 32\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 33\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 554: cannot identify image file <_io.BytesIO object at 0x000001D361029030>\n",
      "Error encountered while sampling pair 316: cannot identify image file <_io.BytesIO object at 0x000001D30DF5CB30>\n",
      "Batch: 34\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 566: cannot identify image file <_io.BytesIO object at 0x000001D35F204630>\n",
      "Batch: 35\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 36\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 37\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 612: cannot identify image file <_io.BytesIO object at 0x000001D361148630>\n",
      "Batch: 38\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 39\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 40\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:26:42,519] Epoch 0 Batch 40 Loss 22.851, ICI Loss 5.786, Entropy loss 17.065.\n",
      "Batch: 41\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 685: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 42\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 43\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 715: cannot identify image file <_io.BytesIO object at 0x000001D6577486D0>\n",
      "Batch: 44\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 45\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 742: cannot identify image file <_io.BytesIO object at 0x000001D657760950>\n",
      "Batch: 46\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 761: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 47\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 48\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 794: cannot identify image file <_io.BytesIO object at 0x000001D361148540>\n",
      "Batch: 49\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 50\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:31:17,906] Epoch 0 Batch 50 Loss 18.996, ICI Loss 3.379, Entropy loss 15.617.\n",
      "Batch: 51\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 832: cannot identify image file <_io.BytesIO object at 0x000001D6576B02C0>\n",
      "Error encountered while sampling pair 841: cannot identify image file <_io.BytesIO object at 0x000001D657748130>\n",
      "Batch: 52\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 53\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 54\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 883: cannot identify image file <_io.BytesIO object at 0x000001D307F77830>\n",
      "Batch: 55\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 904: cannot identify image file <_io.BytesIO object at 0x000001D657749030>\n",
      "Batch: 56\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 57\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 58\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 958: cannot identify image file <_io.BytesIO object at 0x000001D65774B420>\n",
      "Batch: 59\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 969: cannot identify image file <_io.BytesIO object at 0x000001D35FD084F0>\n",
      "Batch: 60\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:36:19,124] Epoch 0 Batch 60 Loss 19.595, ICI Loss 4.607, Entropy loss 14.988.\n",
      "Batch: 61\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 992: cannot identify image file <_io.BytesIO object at 0x000001D361316A20>\n",
      "Batch: 62\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 63\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Saving checkpoint\n",
      "Epoch: 1\n",
      "Training model\n",
      "Batch: 0\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:38:37,119] Epoch 1 Batch 0 Loss 20.006, ICI Loss 3.821, Entropy loss 16.184.\n",
      "Error encountered while sampling pair 17: cannot identify image file <_io.BytesIO object at 0x000001D7891553A0>\n",
      "Batch: 1\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 2\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 3\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 69: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6F830>\n",
      "Error encountered while sampling pair 71: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6F6F0>\n",
      "Batch: 4\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 5\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 6\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 118: cannot identify image file <_io.BytesIO object at 0x000001D307F77E70>\n",
      "Batch: 7\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 8\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 158: cannot identify image file <_io.BytesIO object at 0x000001D657749CB0>\n",
      "Error encountered while sampling pair 883: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6C040>\n",
      "Batch: 9\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 10\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:44:07,850] Epoch 1 Batch 10 Loss 21.283, ICI Loss 3.532, Entropy loss 17.751.\n",
      "Error encountered while sampling pair 182: cannot identify image file <_io.BytesIO object at 0x000001D361009CB0>\n",
      "Batch: 11\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 198: cannot identify image file <_io.BytesIO object at 0x000001D361317E70>\n",
      "Batch: 12\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 13\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 228: cannot identify image file <_io.BytesIO object at 0x000001D361009CB0>\n",
      "Batch: 14\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 249: cannot identify image file <_io.BytesIO object at 0x000001D361315350>\n",
      "Batch: 15\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 16\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 17\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 293: cannot identify image file <_io.BytesIO object at 0x000001D657749170>\n",
      "Batch: 18\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 316: cannot identify image file <_io.BytesIO object at 0x000001D657749170>\n",
      "Batch: 19\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 20\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:49:38,601] Epoch 1 Batch 20 Loss 19.556, ICI Loss 4.225, Entropy loss 15.331.\n",
      "Error encountered while sampling pair 339: cannot identify image file <_io.BytesIO object at 0x000001D35FD08CC0>\n",
      "Batch: 21\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 22\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 23\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 384: cannot identify image file <_io.BytesIO object at 0x000001D361301DA0>\n",
      "Batch: 24\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 415: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6F740>\n",
      "Batch: 25\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 26\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 27\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 460: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 28\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 29\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 30\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 17:55:12,308] Epoch 1 Batch 30 Loss 19.482, ICI Loss 4.896, Entropy loss 14.586.\n",
      "Error encountered while sampling pair 501: cannot identify image file <_io.BytesIO object at 0x000001D361317E70>\n",
      "Batch: 31\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 32\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 33\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 554: cannot identify image file <_io.BytesIO object at 0x000001D307F77E70>\n",
      "Batch: 34\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 566: cannot identify image file <_io.BytesIO object at 0x000001D361317E70>\n",
      "Batch: 35\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 36\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 37\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 612: cannot identify image file <_io.BytesIO object at 0x000001D6576B02C0>\n",
      "Batch: 38\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 39\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 40\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 18:00:45,594] Epoch 1 Batch 40 Loss 18.390, ICI Loss 4.044, Entropy loss 14.346.\n",
      "Batch: 41\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 673: cannot identify image file <_io.BytesIO object at 0x000001D657749CB0>\n",
      "Error encountered while sampling pair 685: cannot identify image file <_io.BytesIO object at 0x000001D657749CB0>\n",
      "Batch: 42\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 43\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 715: cannot identify image file <_io.BytesIO object at 0x000001D361009CB0>\n",
      "Batch: 44\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 45\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 742: cannot identify image file <_io.BytesIO object at 0x000001D361317E70>\n",
      "Batch: 46\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 760: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6EC50>\n",
      "Error encountered while sampling pair 761: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6F150>\n",
      "Batch: 47\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 48\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 794: cannot identify image file <_io.BytesIO object at 0x000001D3611484F0>\n",
      "Batch: 49\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 50\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 18:06:18,788] Epoch 1 Batch 50 Loss 17.069, ICI Loss 3.356, Entropy loss 13.713.\n",
      "Batch: 51\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 832: cannot identify image file <_io.BytesIO object at 0x000001D657760950>\n",
      "Error encountered while sampling pair 841: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 52\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 53\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 54\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 883: cannot identify image file <_io.BytesIO object at 0x000001D6576B0090>\n",
      "Error encountered while sampling pair 118: cannot identify image file <_io.BytesIO object at 0x000001D657748400>\n",
      "Batch: 55\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 904: cannot identify image file <_io.BytesIO object at 0x000001E0DAB6F970>\n",
      "Batch: 56\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 57\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 58\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 958: cannot identify image file <_io.BytesIO object at 0x000001D361317E70>\n",
      "Batch: 59\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 969: cannot identify image file <_io.BytesIO object at 0x000001D657760090>\n",
      "Batch: 60\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "[INFO: 2024-12-16 18:11:53,008] Epoch 1 Batch 60 Loss 17.923, ICI Loss 4.159, Entropy loss 13.764.\n",
      "Batch: 61\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Error encountered while sampling pair 992: cannot identify image file <_io.BytesIO object at 0x000001D6576B0090>\n",
      "Batch: 62\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Batch: 63\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n",
      "backpropagation done\n",
      "step\n",
      "step done\n",
      "Saving checkpoint\n",
      "Epoch: 2\n",
      "Training model\n",
      "Batch: 0\n",
      "Zero_grad\n",
      "Zero_grad done\n",
      "ici + entropy loss\n",
      "ici + entropy loss done\n",
      "backpropagating loss\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 5.01 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m ici_loss \u001b[38;5;241m+\u001b[39m entropy_loss\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackpropagating loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackpropagation done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\function.py:306\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    305\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:313\u001b[0m, in \u001b[0;36mCheckpointFunction.backward\u001b[1;34m(ctx, *args)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone of output has requires_grad=True,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this checkpoint() is not necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[1;32m--> 313\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    315\u001b[0m     inp\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m detached_inputs\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m+\u001b[39m grads\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 5.01 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for _e in range(start_epoch, epochs):\n",
    "    print(f\"Epoch: {_e}\")\n",
    "    print('Training model')\n",
    "    model.train()\n",
    "    for _b, batch in enumerate(train_loader):\n",
    "        print(f\"Batch: {_b}\")\n",
    "        for _k, _v in batch.items():\n",
    "            if isinstance(_v, torch.Tensor):\n",
    "                batch[_k] = _v.cuda()\n",
    "        print('Zero_grad')\n",
    "        opt.zero_grad()\n",
    "        print(\"Zero_grad done\")\n",
    "        print('ici + entropy loss')\n",
    "        ici_loss, entropy_loss = train_step(batch)\n",
    "        print('ici + entropy loss done')\n",
    "        loss = ici_loss + entropy_loss\n",
    "        print('backpropagating loss')\n",
    "        loss.backward()\n",
    "        print('backpropagation done')\n",
    "        print('step')\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        print('step done')\n",
    "\n",
    "        global_step += 1\n",
    "        if _b % print_freq == 0:\n",
    "            logger.info('Epoch %d Batch %d Loss %.3f, ICI Loss %.3f, Entropy loss %.3f.' % (\n",
    "                _e, _b, loss.item(), ici_loss.item(), entropy_loss.item())\n",
    "            )\n",
    "\n",
    "    ckpt = {'state_dict': model.state_dict(), 'optimizer': opt.state_dict(), 'scheduler': scheduler.state_dict(),\n",
    "            'epoch': _e}\n",
    "    print('Saving checkpoint')\n",
    "    torch.save(ckpt, work_dir + '/checkpoints/epoch_%d.pth' % _e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
